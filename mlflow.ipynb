{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking with MLflow\n",
    "\n",
    "MLflow is a powerful tool for managing and tracking machine learning experiments, helping to streamline workflows and analyze results efficiently. In this notebook, we will explore how to use MLflow to log and evaluate models, store essential data, and analyze performance across multiple experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"learning_rate\", 0.01)\n",
    "    mlflow.log_param(\"epochs\", 10)\n",
    "\n",
    "    # Log metrics (in a loop simulating training)\n",
    "    for epoch in range(10):\n",
    "        accuracy = 0.8 + epoch * 0.02  # Simulated accuracy improvement\n",
    "        mlflow.log_metric(\"accuracy\", accuracy, step=epoch)\n",
    "\n",
    "    # Log an artifact (a result file, model, etc.)\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        f.write(\"This is a test artifact.\")\n",
    "    mlflow.log_artifact(\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for Logistic Regression\n",
    "learning_rate = 0.01  # In LogisticRegression, this can be interpreted as the inverse of regularization strength\n",
    "epochs = 10\n",
    "penalty = 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Accuracy: 0.3667\n",
      "Epoch 2/10 - Accuracy: 0.6333\n",
      "Epoch 3/10 - Accuracy: 0.7000\n",
      "Epoch 4/10 - Accuracy: 0.6333\n",
      "Epoch 5/10 - Accuracy: 0.7000\n",
      "Epoch 6/10 - Accuracy: 0.6333\n",
      "Epoch 7/10 - Accuracy: 0.7000\n",
      "Epoch 8/10 - Accuracy: 0.6667\n",
      "Epoch 9/10 - Accuracy: 0.7000\n",
      "Epoch 10/10 - Accuracy: 0.8333\n",
      "Run complete. Check MLflow UI for details.\n"
     ]
    }
   ],
   "source": [
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "    mlflow.log_param(\"epochs\", epochs)\n",
    "    mlflow.log_param(\"penalty\", penalty)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LogisticRegression(penalty=penalty, solver='lbfgs', max_iter=1, warm_start=True)\n",
    "\n",
    "    # Train over multiple \"epochs\" (re-fitting the model)\n",
    "    for epoch in range(epochs):\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict and calculate accuracy\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Log the accuracy as a metric\n",
    "        mlflow.log_metric(\"accuracy\", accuracy, step=epoch)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Save the model as an artifact\n",
    "    model_filename = \"logistic_regression_model.pkl\"\n",
    "    mlflow.sklearn.save_model(model, model_filename)\n",
    "\n",
    "    # Log the saved model as an artifact\n",
    "    mlflow.log_artifact(model_filename)\n",
    "\n",
    "    # Save and log an additional artifact (like a text file)\n",
    "    with open(\"output.txt\", \"w\") as f:\n",
    "        f.write(\"Logistic Regression model for Iris dataset.\")\n",
    "    mlflow.log_artifact(\"output.txt\")\n",
    "\n",
    "    print(\"Run complete. Check MLflow UI for details.\")\n",
    "\n",
    "# Instructions to view the results in MLflow UI:\n",
    "# After running the script, type \"mlflow ui\" in your terminal to start the UI, and navigate to http://localhost:5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## full project with autologging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"Autolog Iris_Classification_Experiment\")\n",
    "\n",
    "# Enable autologging\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a model\n",
    "with mlflow.start_run():\n",
    "    model = LogisticRegression(max_iter=200)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # No need for manual logging; it's handled by autologging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/9f9139606a3f44538936aeb55822a097/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Run '48c5723dc52c4158a3ab0793e7c7193d' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m logged_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns:/48c5723dc52c4158a3ab0793e7c7193d/model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load model as a PyFuncModel.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39mload_model(logged_model)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Predict on a Pandas DataFrame.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\tracing\\provider.py:422\u001b[0m, in \u001b[0;36mtrace_disabled.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m disable()\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 422\u001b[0m     is_func_called, result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    424\u001b[0m     enable()\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:1091\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[0;32m   1087\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(Entity(job\u001b[38;5;241m=\u001b[39mjob_entity))\n\u001b[0;32m   1089\u001b[0m     lineage_header_info \u001b[38;5;241m=\u001b[39m LineageHeaderInfo(entities\u001b[38;5;241m=\u001b[39mentity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1091\u001b[0m local_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(\n\u001b[0;32m   1092\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39mmodel_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path, lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info\n\u001b[0;32m   1093\u001b[0m )\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[0;32m   1096\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:108\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[1;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    artifact_uri: The *absolute* URI of the artifact to download.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m    lineage_header_info: The model lineage header info to be consumed by lineage services.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    107\u001b[0m root_uri, artifact_path \u001b[38;5;241m=\u001b[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001b[1;32m--> 108\u001b[0m repo \u001b[38;5;241m=\u001b[39m get_artifact_repository(artifact_uri\u001b[38;5;241m=\u001b[39mroot_uri)\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[0;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[0;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[0;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[0;32m    115\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:131\u001b[0m, in \u001b[0;36mget_artifact_repository\u001b[1;34m(artifact_uri)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_artifact_repository\u001b[39m(artifact_uri: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArtifactRepository:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    Get an artifact repository from the registry based on the scheme of artifact_uri\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m        requirements.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _artifact_repository_registry\u001b[38;5;241m.\u001b[39mget_artifact_repository(artifact_uri)\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\artifact_repository_registry.py:76\u001b[0m, in \u001b[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001b[1;34m(self, artifact_uri)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repository \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find a registered artifact repository for: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martifact_uri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrently registered schemes are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m     )\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repository(artifact_uri)\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:26\u001b[0m, in \u001b[0;36mRunsArtifactRepository.__init__\u001b[1;34m(self, artifact_uri)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martifact_repository_registry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_artifact_repository\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(artifact_uri)\n\u001b[1;32m---> 26\u001b[0m uri \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(artifact_uri)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo \u001b[38;5;241m=\u001b[39m get_artifact_repository(uri)\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\store\\artifact\\runs_artifact_repo.py:39\u001b[0m, in \u001b[0;36mRunsArtifactRepository.get_underlying_uri\u001b[1;34m(runs_uri)\u001b[0m\n\u001b[0;32m     37\u001b[0m (run_id, artifact_path) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(runs_uri)\n\u001b[0;32m     38\u001b[0m tracking_uri \u001b[38;5;241m=\u001b[39m get_databricks_profile_uri_from_artifact_uri(runs_uri)\n\u001b[1;32m---> 39\u001b[0m uri \u001b[38;5;241m=\u001b[39m get_artifact_uri(run_id, artifact_path, tracking_uri)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mis_runs_uri(uri)  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m add_databricks_profile_info_to_artifact_uri(uri, tracking_uri)\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\artifact_utils.py:52\u001b[0m, in \u001b[0;36mget_artifact_uri\u001b[1;34m(run_id, artifact_path, tracking_uri)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m     47\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA run_id must be specified in order to obtain an artifact uri!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[0;32m     49\u001b[0m     )\n\u001b[0;32m     51\u001b[0m store \u001b[38;5;241m=\u001b[39m _get_store(tracking_uri)\n\u001b[1;32m---> 52\u001b[0m run \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mget_run(run_id)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Maybe move this method to RunsArtifactRepository so the circular dependency is clearer.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mparse\u001b[38;5;241m.\u001b[39murlparse(run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39martifact_uri)\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# avoid an infinite loop\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:699\u001b[0m, in \u001b[0;36mFileStore.get_run\u001b[1;34m(self, run_id)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03mNote: Will get both active and deleted runs.\u001b[39;00m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    698\u001b[0m _validate_run_id(run_id)\n\u001b[1;32m--> 699\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info(run_id)\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    702\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m metadata is in invalid state.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    703\u001b[0m         databricks_pb2\u001b[38;5;241m.\u001b[39mINVALID_STATE,\n\u001b[0;32m    704\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:724\u001b[0m, in \u001b[0;36mFileStore._get_run_info\u001b[1;34m(self, run_uuid)\u001b[0m\n\u001b[0;32m    722\u001b[0m exp_id, run_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_run_root(run_uuid)\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m, databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_DOES_NOT_EXIST\n\u001b[0;32m    726\u001b[0m     )\n\u001b[0;32m    727\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_run_info_from_dir(run_dir)\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info\u001b[38;5;241m.\u001b[39mexperiment_id \u001b[38;5;241m!=\u001b[39m exp_id:\n",
      "\u001b[1;31mMlflowException\u001b[0m: Run '48c5723dc52c4158a3ab0793e7c7193d' not found"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/48c5723dc52c4158a3ab0793e7c7193d/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 18:00:46 WARNING mlflow.utils.autologging_utils: MLflow keras autologging is known to be compatible with 3.0.2 <= keras <= 3.8.0, but the installed version is 3.9.1. If you encounter errors during autologging, try upgrading / downgrading keras to a compatible version, or try upgrading MLflow.\n",
      "c:\\Users\\kkhal\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8782 - loss: 0.4344 - val_accuracy: 0.9600 - val_loss: 0.1336\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1142 - val_accuracy: 0.9695 - val_loss: 0.1035\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0750 - val_accuracy: 0.9725 - val_loss: 0.0898\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0559 - val_accuracy: 0.9779 - val_loss: 0.0766\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0399 - val_accuracy: 0.9798 - val_loss: 0.0704\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"Autolog_Mnist_Experiment\")\n",
    "\n",
    "# Enable autologging for Keras\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
    "\n",
    "# Define a simple neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model within an MLflow run\n",
    "with mlflow.start_run():\n",
    "    model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "\n",
    "# After training, you can access the logged data in the MLflow UI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/03 18:03:10 INFO mlflow.sklearn.utils: Logging the 5 best runs, 22 runs will be omitted.\n",
      "2025/04/03 18:03:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "Best accuracy score:  0.9619047619047619\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set experiment name in MLflow\n",
    "experiment_name = \"GridSearch_RF_Experiment\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Load the dataset\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Set up the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameters for the GridSearch experiment\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100],\n",
    "    \"max_depth\": [3, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Start an MLflow run within a specific experiment\n",
    "with mlflow.start_run():\n",
    "    # Run GridSearch\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Log parameters for each individual trial\n",
    "    for i, params in enumerate(grid_search.cv_results_[\"params\"]):\n",
    "        accuracy = grid_search.cv_results_[\"mean_test_score\"][i]\n",
    "        \n",
    "        # Log each trial with its trial number\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(f\"trial_{i}_{key}\", value)\n",
    "        \n",
    "        # Log the accuracy of each trial as a metric\n",
    "        mlflow.log_metric(f\"trial_{i}_accuracy\", accuracy)\n",
    "\n",
    "    # Log the best model with the best parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    mlflow.sklearn.log_model(best_model, \"best_rf_model\")\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Best parameters found: \", grid_search.best_params_)\n",
    "    print(\"Best accuracy score: \", grid_search.best_score_)\n",
    "\n",
    "    # Results can be viewed in the MLflow UI after running the code at the link: http://localhost:5000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
